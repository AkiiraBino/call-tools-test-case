## 1. Какой опыт коммерческой разработки на позиции ML?
#### ДНС технологии - ML engineer
Разработан сервис видеоаналитики, который читает видеопотоки с филиалов, предобрабатывает и получает полезные метаданные, благодаря чему у компании появился новый источник данных. 
___
Разработан парсер корпоративных ресурсов для создания единой базы знаний, в следствии разработан сервис RAG LLM, который ускорил взаимодействие с базой знаний. Аналогично проведено исследование SOTA архитектур, тюниннг эмбеддера для построения базы знаний и поиск по запросу.
___
Исследование по теме верификации рукописных подписей, разработка сверточных моделей, валидация
#### BookCourt - Backend developer
Разработка рекомендательной системы на основе контента в сфере книжного ритейла, благодаря которой выросло количество продаж. Оптимизация пайплайна и написание API для модели.
#### ФГБОУ ВО Владивостокский Государственный Университет - Лаборант
Научные исследования по теме машинного обучения в информационной безопасности. Разработка архитектур для статического анализа кода на основе TF-IDF и нейронных сетей. По результатам опубликованы несколько статей, в том числе ВАК РФ, победы на международных конференциях
## 2. У вас есть опыт разработки своих моделей нейронных сетей или применения, существующих open source решений? Если да, опишите проекты или задачи, в которых вы применяли нейронные сети.
При разработке сервиса видеоаналитики и RAG LLM были проанализированы SOTA архитектуры (актуальные на тот момент YOLOv8-v10, доработанный ResNet. В RAG LLM mistral7b и российские файнтюны этой модели).
При исследовании верификации подписей найдены несколько архитектур, подтвердивших свою эффективность при верификации. Архитектуры были доработаны (добавлены batch normalization слои и dropout). Также проведено сравнение с дообученными ResNet разных размеров.
При исследованиях по теме машинного обучения в информационной безопасности также были разработаны архитектуры нейронных сетей, ограничились небольшой полносвязной сетью.
Проходил курс от DeepLearningSchool в рамках которого надо было реализовать несколько архитектур по научным статьям и соответствующие функции потерь/метрики, например U-Net
В карьере, в основном, применялись нейронные сети. Достаточно мало практического опыта в классическом машинном обучении.
## 3. С какими архитектурами нейронных сетей знакомы?
В основном со связанными с CV (сверточные) и NLP (трансформеры), например YOLO, ResNet, U-Net из сверточных и Mistral, GPT, BERT из трансформеров.
## 4. Какой язык программирования вы используете в своей работе?
Только Python
## 5. Какие инструменты/фреймворки применяете и для каких задач?
Elasticsearch для векторного хранилища, docker/docker-compose для контейнерезации, git как система контроля версий, zeromq как брокер, minio как объектное хранилище, cvat для разметки изображений. Применял на одной из работ FastAPI, SQLAlchemy 2.0 + asyncpg, alembic при разработке API модели.
Из DL torch, sklearn.
## 6. С какими библиотеками приходится работать?
PyTorch, scikit-learn, zmq,  FastApi, SQLAlchemy 2.0 + asyncpg, alembic, transformers, datasets, langchain, atlassian-python-api, llama-cpp, opencv, ultralytics
## 7. Работали ли ранее с SQL, (чистые запросы, ORM), какие ORM использовали? Какие СУБД использовали в работе (Sqlite, Postgresql, MySQL, MongoDb, ClickHouse, и др.)? Каков максимальный размер БД с которой был опыт работы?
В основном использовал sqlalchemy и postgresql, был опыт в студенчестве с mysql и sqlite. Также работал с чистыми запросами. Максимальный размер БД около 1.5 миллионов записей для реляционных баз, около 1 миллона для векторного хранилища, в районе 100гб для объектного.
## 8. С какими сложностями приходилось сталкиваться при разработке и применении нейронных сетей?
Мало документации, для хорошего понимания требуется потратить время на прочтение статьи, которой может и не быть, или же наоборот может не быть времени.
## 9. Опишите пайплайн обучения модели.
Перед обучением следует провести разведочный анализ данных, их чистку при потребности, качество. Далее решить как обучаем (k-fold, просто разбиение на три выборки). Предположим, что разбили на тестовое, валидационное и тренировочное подмножества. Для тренировочного подмножества определяем аугментации, если их возможно применить. Далее обычно тестирую, обучается ли вообще модель на данных с разными lr (обычно пробую сначала дефолтное, потом 1e-3, 1e-5), можно попробовать разные оптимизаторы, но классика сейчас - AdamW, работает в большинстве случаев хорошо. По метрикам train и val определяем, не переобучается ли модели. Полученный лучший результат можно считать бейзлайном. Далее тесты с гиперпараметрами, возможно Grid- или RandomSearch. Повторяем процесс итерационно до получения приемлемого результата. При переобучении можно попробовать поиграться с dropout, поменять аугментации или добавить новые, добавть BN слои. Полученные топ-n моделей можно оценить на тестовой выборке и далее пробовать A/B тесты, канареечную выкатку и др. В идеале процесс по большей части вмешательство человека требуется только при первичном исследовании, а далее пайплайн автоматизирован.